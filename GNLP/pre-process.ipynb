{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "\n",
    "from resources.logger import log\n",
    "\n",
    "# usage of counters : https://docs.python.org/2/library/collections.html\n",
    "from ftfy import fix_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-11 20:56:46,601\tINFO -- MainProcess <ipython-input-449-8d1b7e0d6f71>:3 -- Welcome to the Georgian NLP toolset demo\n"
     ]
    }
   ],
   "source": [
    "# Init stuff\n",
    "# emit a warning to the puny Humans\n",
    "log.info('Welcome to the Georgian NLP toolset demo')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "outputs": [],
   "source": [
    "# functions\n",
    "def file_path(file_name):\n",
    "    \"\"\"generates abs path relative to the Package and modules\"\"\"\n",
    "    data_dir = os.path.abspath('')\n",
    "    f_path = os.path.join(data_dir, file_name)\n",
    "    # check if the path exists\n",
    "    if os.path.exists(f_path):\n",
    "        return f_path\n",
    "    else:\n",
    "        raise FileNotFoundError\n",
    "\n",
    "def is_not_printable(word, letters_only = True):\n",
    "    \"\"\"\n",
    "    Checks if the string contains the printable symbols\n",
    "    :param word:\n",
    "    :param letters_only:\n",
    "    :return True or False:\n",
    "    \"\"\"\n",
    "\n",
    "    for char in word:\n",
    "        if char not in letters:\n",
    "            return True\n",
    "\n",
    "\n",
    "def sizeof_fmt(file_size, suffix='B'):\n",
    "    \"\"\"\n",
    "    Returns the Human Readable file volume unit from num\n",
    "    :param suffix: default\n",
    "    :param file_size: file size in integer\n",
    "    :return:\n",
    "    ref: https://stackoverflow.com/questions/1094841/reusable-library-to-get-human-readable-version-of-file-size\n",
    "    \"\"\"\n",
    "    for unit in ['', 'Ki', 'Mi', 'Gi', 'Ti', 'Pi', 'Ei', 'Zi']:\n",
    "        if abs(file_size) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (file_size, unit, suffix)\n",
    "        file_size /= 1024.0\n",
    "    return \"%.1f%s%s\" % (file_size, 'Yi', suffix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "outputs": [],
   "source": [
    "numbers = set(\"0123456789\")\n",
    "symbols = set(\"!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c\")\n",
    "letters = set('ქწერტყუიოპჭღთასდფგჰჯკლშჟ₾ზხცვბნმძჩ')\n",
    "printable = set().union(*[numbers, symbols, letters])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "outputs": [],
   "source": [
    "class FileToProcess():\n",
    "    def __init__(self, file_name=None, stop_words=\"data/stops.txt\"):\n",
    "\n",
    "        if not file_name:\n",
    "            raise ValueError(\"Init FileToProcess class with path to the file as file_name argument \")\n",
    "\n",
    "        self.file_name = file_name\n",
    "        self.__path = file_path(file_name)\n",
    "        self.__status = os.stat(self.__path)\n",
    "        self.__file_object = None\n",
    "\n",
    "        self.stop_words = set(line.strip() for line in open(file_path(stop_words), encoding='utf-8'))\n",
    "        self.sequence = []\n",
    "        self.file_size = sizeof_fmt(self.__status.st_size)\n",
    "\n",
    "    def load_file(self, max_num_of_lines = -1):\n",
    "        with open(self.__path, mode='r', encoding='utf-8') as text_file:\n",
    "            for n, line in enumerate(text_file):\n",
    "\n",
    "                if n == max_num_of_lines:\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    fix_encoding(line)\n",
    "                    line = line.strip('\\n')\n",
    "                    self.sequence.append(line)\n",
    "\n",
    "                except Exception as error:\n",
    "                    print(f\"During handling the sentence \\\"{line}\\\", following error has occured: {error}\")\n",
    "        # Finally:\n",
    "        log.info(f'Number of lines in sequence: {len(self.sequence)}')\n",
    "\n",
    "    def __preprocess_text(self, text, min_sentence_size=3, min_word_size=2, max_word_size=25):\n",
    "        \"\"\"preprocess text for NLP tasks\"\"\"\n",
    "        tokens = text.split()\n",
    "        if len(tokens) <= min_sentence_size:\n",
    "            return None\n",
    "        # Removing prefixed 'b'\n",
    "        text = re.sub(r'^b\\s+', '', text)\n",
    "        # Url Removal\n",
    "        text = re.sub(r'http\\S+', '',text)\n",
    "        # Number Removal\n",
    "        text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", '', text)\n",
    "        # mail removal\n",
    "        text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "        # Remove all the special characters\n",
    "        text = re.sub(r'\\W', ' ', text)\n",
    "        # remove all single characters\n",
    "        text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "        # Remove single characters from the start\n",
    "        text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "        # Substituting multiple spaces with single space\n",
    "        text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "        # Converting to Lowercase\n",
    "        text = text.lower()\n",
    "        # Lemmatization - missing\n",
    "        tokens = text.split()\n",
    "\n",
    "        index = len(tokens) - 1\n",
    "        while index >= 0:\n",
    "            word = tokens[index]\n",
    "            if is_not_printable(word) or word in self.stop_words or len(word) < min_word_size or len(word) > max_word_size:\n",
    "                tokens.pop(index)\n",
    "            index -= 1\n",
    "        if len(tokens) < min_sentence_size:\n",
    "            return None\n",
    "\n",
    "        preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "        return preprocessed_text\n",
    "\n",
    "    def pre_process(self):\n",
    "        index = len(self.sequence) - 1\n",
    "        log.info(f'Number of lines before pre-pro: {index}')\n",
    "        while index >= 0:\n",
    "            sentence = self.sequence[index]\n",
    "            if pre_processed_sentence := self.__preprocess_text(sentence):\n",
    "                # update sentence with preprocessed version\n",
    "                # log.info(f\"replaceing: {self.sequence[index]} > {pre_processed_sentence}\")\n",
    "                self.sequence[index] = pre_processed_sentence\n",
    "            else:\n",
    "                # pop sentence from sequence\n",
    "                #log.info(f\"popping: {self.sequence[index]} \")\n",
    "                self.sequence.pop(index)\n",
    "            index -= 1\n",
    "        log.info(f'Number of lines after pre-pro: {len(self.sequence)}')\n",
    "\n",
    "    def save_to_file(self, filename=None):\n",
    "        if not filename:\n",
    "            file_name = f\"{self.file_name.split('.')[0]}_pre_processed.txt\"\n",
    "            with open(file_name, 'w', encoding=\"utf-8\") as output:\n",
    "                for sentence in self.sequence:\n",
    "                    output.write(str(sentence) + '\\n')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Obj of file at: {self.__path}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "outputs": [],
   "source": [
    "# load the file\n",
    "text_file = FileToProcess('data/corpuses/kawiki-latest-pages-articles_preprocessed.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-11 20:56:46,682\tINFO -- MainProcess <ipython-input-452-cc3fc16935ac>:31 -- Number of lines in sequence: 50\n"
     ]
    },
    {
     "data": {
      "text/plain": "50"
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file.load_file(max_num_of_lines=50)\n",
    "len(text_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "outputs": [],
   "source": [
    "# text_file.sequence.append(\"რედაქციის ელ-ფოსტა: resonancenewspaper@yahoo.com\")\n",
    "# text_file.sequence.append(\"მე ვარ ცა იმ ქალაქების თავზე\")\n",
    "# print(text_file.sequence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-11 20:56:46,711\tINFO -- MainProcess <ipython-input-452-cc3fc16935ac>:74 -- Number of lines before pre-pro: 49\n",
      "2021-07-11 20:56:46,714\tINFO -- MainProcess <ipython-input-452-cc3fc16935ac>:86 -- Number of lines after pre-pro: 49\n"
     ]
    }
   ],
   "source": [
    "text_file.pre_process()\n",
    "# print(text_file.sequence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "outputs": [],
   "source": [
    "text_file.save_to_file()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"იმ\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}