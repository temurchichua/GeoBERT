# GeoBERT text classification
**ქართულენოვანი BERT multi-class ტექსტური კლასიფიკაციის მოდელი HuggingFace და Simple Transformers-ის დახმარებით.**

## სარჩევი

1. [**შესავალი**](#შესავალი)

## შესავალი

ინტერნეტში არსებული ტუტორიალების და პოსტების უმრავლესობა გვასწავლის როგორ გამოვიყენოთ BERT-ის  არქიტექტურაზე დაფუძნებული ინგლისურ ენოვანი ტექსტის კლასიფიკაციის, სენტიმენტ ანალიზის, კითხვა-პასუხის ან ტექსტის გენერატორი მოდელები. ჩემი ამოცანაა შევძლო ქართულ ენაზე მსგავსი ოპერაციების ჩატარება და ვიწყებ ტექსტის კლასიფიკაციის მოდელით.

## რესურსები
1. [GitHub: google-research_BERT](https://github.com/google-research/bert)
2. [NLP Models Tensorflow](https://github.com/huseinzol05/NLP-Models-Tensorflow/tree/master/spelling-correction)
3. [How to train a new language model from scratch using Transformers and Tokenizers](https://huggingface.co/blog/how-to-train)
4. [Transformer: A Novel Neural Network Architecture for Language Understanding](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)
5. https://www.freecodecamp.org/news/google-bert-nlp-machine-learning-tutorial/
6. https://towardsdatascience.com/bert-text-classification-in-a-different-language-6af54930f9cb
